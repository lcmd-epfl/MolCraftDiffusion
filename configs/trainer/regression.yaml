_target_: MolecularDiffusion.runmodes.train.OptimSchedulerFactory
optimizer_choice: "adam" # adam, adamw, amsgrad, radam, 
lr: 5e-4
eps: 1e-8
weight_decay: 1e-12
betas: [0.9, 0.999]
foreach: False
num_epochs: 200
scheduler: reducelronplateau # None, steplr, multisteplr, exponentiarlr, cosineannealing, caws, onecyclelr, reducelronplateau       
scheduler_kwargs:
  mode: "min"
  factor: 0.5
  patience: 10
validation_interval: 3
batch_size: ${data.batch_size}
queue_size: 0
init_grad_norm: null
ema_decay: 0.00
gradient_clip_mode: norm # value or norm
grad_clip_value: 1000
chkpt_path: 
output_path: logs
precision: 32 # 16, 32, bf16